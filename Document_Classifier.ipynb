{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaj2701/Document_Classifier/blob/main/Document_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA89GS7sz373",
        "outputId": "4f1a4214-a5a4-437b-f8ac-cf74e943cda7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter number of files to generate: 100000\n",
            "Generated dataset with 100000 records\n",
            "\n",
            "Total Sensitive Files: 41588\n",
            "Total Non-Sensitive Files: 58412\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Configuration\n",
        "PATHS = [\n",
        "    \"/home/docs/\", \"/mnt/dev/\", \"C:\\\\Users\\\\\", \"/srv/records/\", \"/var/logs/\", \"/home/downloads/\",\n",
        "    \"/mnt/data/\", \"C:\\\\Program Files\\\\\", \"/srv/shared/\", \"/tmp/files/\", \"/home/user/Documents/\",\n",
        "    \"/mnt/backup/\", \"C:\\\\Users\\\\Public\\\\\", \"/var/tmp/\", \"/home/admin/logs/\", \"/mnt/secure/\",\n",
        "    \"/srv/storage/\", \"C:\\\\Windows\\\\Temp\\\\\", \"/var/spool/\", \"/home/common/\", \"/mnt/archive/\",\n",
        "    \"C:\\\\Users\\\\Default\\\\\", \"/etc/configs/\", \"/srv/logs/\", \"/var/backups/\", \"/home/shared/\",\n",
        "    \"/mnt/logs/\", \"C:\\\\Windows\\\\System32\\\\\", \"/tmp/storage/\", \"/srv/docs/\", \"/var/local/\",\n",
        "    \"/home/system/\", \"/mnt/mounts/\", \"C:\\\\Users\\\\Administrator\\\\\", \"/etc/logs/\", \"/srv/users/\",\n",
        "    \"/var/tmpdata/\", \"/home/backup/\", \"/mnt/files/\", \"C:\\\\Temp\\\\\", \"/srv/temp/\", \"/var/db/\",\n",
        "    \"/home/data/\", \"/mnt/devices/\", \"C:\\\\Users\\\\Guest\\\\\", \"/srv/backup/\", \"/var/lib/\",\n",
        "    \"/home/local/\", \"/mnt/storage/\", \"C:\\\\Users\\\\Desktop\\\\\", \"/srv/configs/\", \"/var/run/\",\n",
        "    \"/home/media/\", \"/mnt/projects/\", \"C:\\\\Users\\\\Documents\\\\\", \"/srv/system/\", \"/var/tmp_storage/\"\n",
        "]\n",
        "\n",
        "SENSITIVE_KEYWORDS = [\n",
        "    # Financial Documents\n",
        "    \"bank\", \"Bank_Statement\", \"loan\", \"credit\", \"debit\", \"salary\", \"salary_slip\",\n",
        "    \"transaction\", \"invoice\", \"billing\", \"payment\", \"account\", \"tax\", \"gst\", \"receipt\",\n",
        "    \"balance_sheet\", \"financial_report\", \"audit\", \"expense\", \"investment\", \"cheque\", \"ledger\",\n",
        "    \"payslip\", \"funds\", \"securities\", \"loan_document\", \"mortgage\", \"financial_statement\",\n",
        "\n",
        "    # Identity Proofs\n",
        "    \"aadhar\", \"aadhar_card\", \"aadhaar\", \"aadhaar_card\", \"pan\", \"pan_card\", \"passport\", \"voter_id\",\n",
        "    \"driving_license\", \"dl\", \"ssn\", \"social_security\", \"national_id\", \"identity_proof\", \"kyc\",\n",
        "    \"government_id\", \"citizenship\", \"residence_permit\", \"work_permit\", \"birth_certificate\",\n",
        "    \"visa\", \"id_card\", \"national_insurance\", \"itin\", \"sin\", \"personal_id\",\n",
        "\n",
        "    # Legal Documents\n",
        "    \"nda\", \"contract\", \"agreement\", \"legal\", \"lawsuit\", \"court\", \"license\", \"policy\",\n",
        "    \"confidential\", \"privileged\", \"disclosure\", \"terms_conditions\", \"compliance\",\n",
        "    \"non_disclosure\", \"intellectual_property\", \"patent\", \"litigation\", \"testimony\", \"copyright\",\n",
        "    \"trademark\", \"corporate_law\", \"privacy_policy\", \"terms_of_service\", \"arbitration\",\n",
        "\n",
        "    # Medical Records\n",
        "    \"medical\", \"patient\", \"health\", \"insurance\", \"prescription\", \"treatment\", \"hospital\",\n",
        "    \"diagnosis\", \"lab_report\", \"clinical\", \"medical_record\", \"doctor\", \"surgery\",\n",
        "    \"emergency\", \"pharmacy\", \"medication\", \"mental_health\", \"covid\", \"xray\",\n",
        "    \"scan\", \"blood_test\", \"radiology\", \"disease\", \"disability\", \"ehr\", \"emr\", \"hospital_bill\",\n",
        "\n",
        "    # Corporate Data\n",
        "    \"internal\", \"client\", \"project_details\", \"business\", \"strategy\", \"proprietary\", \"confidential\",\n",
        "    \"proposal\", \"presentation\", \"meeting_minutes\", \"organization\", \"roadmap\", \"budget\",\n",
        "    \"profit_loss\", \"shareholders\", \"board_meeting\", \"executive_summary\", \"sales_data\",\n",
        "    \"market_analysis\", \"financial_forecast\", \"investor_report\", \"sensitive_data\", \"pricing\",\n",
        "    \"supplier_contract\", \"partnership\", \"company_policy\", \"hr_policy\", \"employee_data\",\n",
        "\n",
        "    # Variations & Naming Conventions\n",
        "    \"aadharcard\", \"aadhaarcard\", \"panCard\", \"bankStatement\", \"salarySlip\", \"confidential_doc\",\n",
        "    \"medicalRecord\", \"financials\", \"auditReport\", \"investmentPortfolio\", \"loanAgreement\",\n",
        "    \"passportCopy\", \"nda_doc\", \"contractAgreement\", \"policy_doc\", \"balanceSheet\", \"billingInvoice\",\n",
        "    \"contract_doc\", \"legal_doc\", \"corporate_policy\", \"business_strategy\", \"tax_return\",\n",
        "    \"budget_plan\", \"investment_summary\", \"data_privacy\", \"cybersecurity\", \"payroll\", \"cibil_score\",\n",
        "\n",
        "    #Corporate\n",
        "    \"HR\", \"Admin\", \"CEO\"\n",
        "]\n",
        "\n",
        "NON_SENSITIVE_KEYWORDS = [\n",
        "    # General Documents\n",
        "    \"notes\", \"lecture\", \"assignment\", \"homework\", \"project_plan\", \"task_list\", \"meeting_agenda\",\n",
        "    \"schedule\", \"calendar\", \"worksheet\", \"tutorial\", \"reference\", \"guide\", \"instructions\", \"checklist\",\n",
        "    \"minutes\", \"summary\", \"report\", \"presentation\", \"handbook\", \"newsletter\", \"brochure\", \"flyer\",\n",
        "    \"poster\", \"announcement\", \"memo\", \"proposal\", \"research\", \"whitepaper\", \"article\", \"blog\",\n",
        "    \"press_release\", \"news\", \"bulletin\", \"journal\", \"review\", \"case_study\", \"survey\", \"questionnaire\",\n",
        "\n",
        "    # Public Information\n",
        "    \"public_notice\", \"government_notice\", \"circular\", \"press_announcement\", \"legal_notice\", \"policy_brief\",\n",
        "    \"open_data\", \"transparency_report\", \"census_data\", \"statistics\", \"weather_report\", \"market_report\",\n",
        "    \"trade_analysis\", \"industry_insights\", \"public_speech\", \"conference_paper\", \"open_access\",\n",
        "\n",
        "    # Educational Documents\n",
        "    \"course_material\", \"syllabus\", \"curriculum\", \"class_notes\", \"school_report\", \"university_brochure\",\n",
        "    \"education_policy\", \"exam_papers\", \"sample_questions\", \"study_guide\", \"revision_notes\", \"teacher_guide\",\n",
        "    \"student_handbook\", \"scholarship_info\", \"research_paper\",\n",
        "\n",
        "    # Technical and IT Documents\n",
        "    \"user_manual\", \"installation_guide\", \"configuration\", \"technical_doc\", \"api_documentation\",\n",
        "    \"troubleshooting_guide\", \"faq\", \"release_notes\", \"software_update\", \"patch_notes\", \"product_specs\",\n",
        "    \"system_requirements\", \"technical_report\", \"design_doc\", \"coding_guidelines\", \"development_notes\",\n",
        "    \"product_catalog\", \"feature_list\", \"wireframe\", \"prototype\", \"architecture_diagram\", \"network_plan\",\n",
        "\n",
        "    # Business and Corporate Documents\n",
        "    \"invoice_template\", \"budget_plan\", \"marketing_plan\", \"branding_guide\", \"product_launch\",\n",
        "    \"corporate_strategy\", \"sales_forecast\", \"revenue_report\", \"expense_summary\", \"workflow_document\",\n",
        "    \"operation_manual\", \"team_meeting\", \"status_update\", \"business_roadmap\", \"partnership_agreement\",\n",
        "\n",
        "    # Creative and Media Content\n",
        "    \"script\", \"storyboard\", \"podcast_notes\", \"song_lyrics\", \"music_sheet\", \"artwork\", \"animation\",\n",
        "    \"illustration\", \"photo_collection\", \"design_mockup\", \"video_script\", \"documentary_script\",\n",
        "    \"book_draft\", \"novel_outline\", \"manuscript\", \"poetry\", \"fanfiction\", \"comic_strip\", \"sketchbook\",\n",
        "\n",
        "    # Travel and Events\n",
        "    \"itinerary\", \"flight_details\", \"hotel_booking\", \"trip_plan\", \"packing_list\", \"restaurant_review\",\n",
        "    \"travel_blog\", \"road_trip\", \"tourist_guide\", \"visa_guide\", \"city_map\", \"local_attractions\",\n",
        "    \"event_schedule\", \"concert_tickets\", \"festival_info\", \"conference_agenda\", \"movie_list\",\n",
        "    \"book_club\", \"sports_schedule\", \"game_rules\",\n",
        "\n",
        "    # Lifestyle and Personal Documents\n",
        "    \"recipe\", \"cooking_tips\", \"fitness_plan\", \"diet_chart\", \"grocery_list\", \"home_maintenance\",\n",
        "    \"garden_tips\", \"pet_care\", \"budget_tracker\", \"financial_planner\", \"expense_sheet\", \"task_manager\",\n",
        "    \"time_tracker\", \"journal_entry\", \"diary\", \"self_improvement\", \"meditation_notes\", \"goal_setting\",\n",
        "    \"motivational_quotes\", \"daily_log\", \"bucket_list\",\n",
        "\n",
        "    # Miscellaneous Variations\n",
        "    \"draft_project_plan\", \"updated_notes\", \"final_presentation\", \"backup_report\", \"sample_worksheet\",\n",
        "    \"new_task_list\", \"old_summary\", \"copy_meeting_agenda\", \"v1_memo\", \"v2_blog\", \"report_overview\",\n",
        "    \"info_handbook\", \"updated_case_study\", \"checklist_data\", \"public_notice_log\", \"survey_record\",\n",
        "    \"journal_entry_details\", \"meeting_notes_file\", \"release_notes_info\", \"research_paper_log\",\n",
        "    \"statistics_report_data\", \"course_material_info\", \"development_notes_file\", \"architecture_diagram_details\",\n",
        "    \"software_update_log\", \"financial_planner_report\", \"budget_plan_info\", \"partnership_agreement_file\",\n",
        "    \"event_schedule_details\", \"travel_blog_overview\", \"trip_plan_file\", \"visa_guide_record\", \"daily_log_info\",\n",
        "    \"motivational_quotes_record\", \"meditation_notes_file\", \"grocery_list_details\", \"home_maintenance_log\",\n",
        "    \"self_improvement_doc\", \"draft_budget_plan\", \"updated_coding_guidelines\", \"final_journal_entry\",\n",
        "    \"backup_lecture_notes\", \"sample_diary\", \"new_travel_blog\", \"old_study_guide\", \"copy_script\", \"v1_poetry\",\n",
        "    \"v2_comic_strip\", \"task_list_file\", \"article_overview\", \"business_roadmap_log\", \"invoice_template_data\",\n",
        "    \"marketing_plan_record\", \"patch_notes_doc\", \"troubleshooting_guide_file\", \"technical_doc_report\",\n",
        "    \"product_specs_overview\", \"schedule_log\", \"case_study_details\", \"industry_insights_record\",\n",
        "    \"reference_data\", \"workflow_document_log\", \"lecture_notes_file\", \"university_brochure_data\",\n",
        "    \"transparency_report_overview\", \"legal_notice_details\", \"updated_policy_brief\", \"sample_transparency_report\",\n",
        "    \"budget_tracker_file\", \"travel_blog_notes\", \"final_conference_agenda\", \"updated_movie_list\", \"book_club_info\",\n",
        "    \"sports_schedule_report\", \"game_rules_file\", \"script_record\", \"storyboard_overview\", \"daily_log_entry\",\n",
        "    \"self_improvement_notes\", \"backup_technical_doc\", \"sample_configuration\", \"new_software_update\",\n",
        "    \"old_release_notes\", \"copy_patch_notes\", \"v1_api_documentation\", \"v2_troubleshooting_guide\",\n",
        "    \"expense_summary_log\", \"corporate_strategy_file\", \"revenue_report_details\", \"festival_info_record\",\n",
        "    \"visa_guide_log\", \"concert_tickets_data\"\n",
        "]\n",
        "\n",
        "EXTENSIONS = [\".pdf\", \".docx\", \".xlsx\", \".txt\", \".pptx\", \".csv\"]\n",
        "OWNERS = [\"Finance\", \"HR\", \"IT\", \"Marketing\", \"Operations\"]\n",
        "PERMISSIONS = [\"Restricted\", \"Confidential\", \"Public\", \"Internal\"]\n",
        "\n",
        "# Generate random file size using log-normal distribution\n",
        "def random_size():\n",
        "    return int(np.random.lognormal(mean=6, sigma=1.2))  # 1KB-500MB\n",
        "\n",
        "# Generate random dates with temporal patterns\n",
        "def random_date(is_sensitive):\n",
        "    start_date = datetime.now() - timedelta(days=5 * 365)\n",
        "    random_days = random.randint(0, 5 * 365)\n",
        "    creation_date = start_date + timedelta(days=random_days)\n",
        "\n",
        "    # Sensitive files are modified more recently\n",
        "    if is_sensitive:\n",
        "        modified_date = creation_date + timedelta(days=random.randint(0, 7))\n",
        "    else:\n",
        "        modified_date = creation_date + timedelta(days=random.randint(0, 365))\n",
        "\n",
        "    return creation_date.strftime(\"%Y-%m-%d\"), modified_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Calculate sensitivity score\n",
        "def calculate_sensitivity_score(row):\n",
        "    weights = {\"Keyword\": 50, \"Permissions\": 5, \"Owner\": 15, \"Extension\": 20, \"Size\": 5, \"Date\": 5}\n",
        "    score = 0\n",
        "    score += weights[\"Keyword\"] * row[\"has_sensitive_keyword\"]\n",
        "    score += weights[\"Permissions\"] * (row[\"permissions\"] == \"Restricted\")\n",
        "    score += weights[\"Owner\"] * (row[\"owner\"] in [\"Finance\", \"HR\"])\n",
        "    score += weights[\"Extension\"] * (row[\"extension\"] in [\".pdf\", \".docx\"])\n",
        "    score += weights[\"Size\"] * (row[\"size\"] > 1000)\n",
        "    score += weights[\"Date\"] * ((pd.to_datetime('today') - pd.to_datetime(row[\"created\"])).days < 180)\n",
        "\n",
        "    return 1 if score >= random.uniform(45, 60) else 0\n",
        "    # return 1 if score >= 50 else 0\n",
        "\n",
        "# Generate synthetic metadata\n",
        "def generate_metadata(num_files):\n",
        "    data = []\n",
        "    for _ in range(num_files):\n",
        "        is_sensitive = random.choice([True, False])\n",
        "        keyword = random.choice(SENSITIVE_KEYWORDS if is_sensitive else NON_SENSITIVE_KEYWORDS)\n",
        "        path = random.choice(PATHS)\n",
        "        ext = random.choice(EXTENSIONS)\n",
        "        owner = random.choice(OWNERS)\n",
        "        permissions = random.choice(PERMISSIONS)\n",
        "        size = random_size()\n",
        "        creation_date, modified_date = random_date(is_sensitive)\n",
        "\n",
        "        record = {\n",
        "            \"filename\": f\"{path}{keyword}{ext}\",\n",
        "            \"extension\": ext,\n",
        "            \"owner\": owner,\n",
        "            \"permissions\": permissions,\n",
        "            \"size\": size,\n",
        "            \"created\": creation_date,\n",
        "            \"modified\": modified_date,\n",
        "            \"has_sensitive_keyword\": is_sensitive,\n",
        "            \"label\": 0  # Will be updated based on score\n",
        "        }\n",
        "        data.append(record)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df['label'] = df.apply(calculate_sensitivity_score, axis=1)\n",
        "\n",
        "    flip_indices = random.sample(range(len(df)), int(0.05 * len(df)))\n",
        "    df.loc[flip_indices, \"label\"] = 1 - df.loc[flip_indices, \"label\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    num_files = int(input(\"Enter number of files to generate: \"))\n",
        "    df = generate_metadata(num_files)\n",
        "    df.to_csv(\"file_metadata.csv\", index=False)\n",
        "    print(f\"Generated dataset with {len(df)} records\")\n",
        "\n",
        "    # print(\"\\nSample Data:\")\n",
        "    # print(df.head())\n",
        "\n",
        "    print(\"\\nTotal Sensitive Files:\", df[\"label\"].sum())\n",
        "    print(\"Total Non-Sensitive Files:\", len(df) - df[\"label\"].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3xsqNii0NZn",
        "outputId": "ab1d3469-e057-45c2-db90-0bd8fcd1f7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.92      0.91     14603\n",
            "           1       0.89      0.85      0.87     10397\n",
            "\n",
            "    accuracy                           0.89     25000\n",
            "   macro avg       0.89      0.89      0.89     25000\n",
            "weighted avg       0.89      0.89      0.89     25000\n",
            "\n",
            "\n",
            "Model trained and saved successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import joblib\n",
        "# import shap\n",
        "\n",
        "def train_model():\n",
        "    df = pd.read_csv(\"file_metadata.csv\", parse_dates=['created', 'modified'])\n",
        "\n",
        "    # Feature engineering\n",
        "    df['days_since_creation'] = (pd.to_datetime('today') - df['created']).dt.days\n",
        "    df['days_since_modification'] = (pd.to_datetime('today') - df['modified']).dt.days\n",
        "\n",
        "    features = df[[\n",
        "        'extension', 'owner', 'permissions', 'size',\n",
        "        'days_since_creation', 'days_since_modification',\n",
        "        'has_sensitive_keyword'\n",
        "    ]]\n",
        "    target = df['label']\n",
        "\n",
        "    # Preprocessing\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('cat', OneHotEncoder(handle_unknown='infrequent_if_exist'), ['extension', 'owner', 'permissions']),\n",
        "        ('num', StandardScaler(), ['size', 'days_since_creation', 'days_since_modification']),\n",
        "        ('bool', 'passthrough', ['has_sensitive_keyword'])\n",
        "    ])\n",
        "\n",
        "    # Model pipeline\n",
        "    model = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(\n",
        "            n_estimators=150,\n",
        "            max_depth=4,\n",
        "            learning_rate=0.05,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        features, target, test_size=0.25, random_state=42, stratify=target\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Model Evaluation:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Save model\n",
        "    joblib.dump(model, 'sensitivity_classifier.joblib')\n",
        "    print(\"\\nModel trained and saved successfully\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAoiIkco0R-4",
        "outputId": "3feec4f0-3071-4fbe-f61c-063c307e5003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter file path: /content/EAadhar_123.pdf\n",
            "Prediction Result:\n",
            "Classification: Sensitive\n",
            "Confidence: 95.0%\n",
            "\n",
            "Enter file path: /content/Meeting_Notes.docx\n",
            "Prediction Result:\n",
            "Classification: Non-Sensitive\n",
            "Confidence: 92.4%\n",
            "\n",
            "Enter file path: /content/profile_photo.jpg\n",
            "Prediction Result:\n",
            "Classification: Non-Sensitive\n",
            "Confidence: 89.2%\n",
            "\n",
            "Enter file path: /content/Pancard.pdf\n",
            "Prediction Result:\n",
            "Classification: Sensitive\n",
            "Confidence: 94.4%\n",
            "\n",
            "Enter file path: /content/HKDRF_2025.pdf\n",
            "Prediction Result:\n",
            "Classification: Non-Sensitive\n",
            "Confidence: 86.4%\n",
            "\n",
            "Enter file path: /content/Bank_Statement.xlsx\n",
            "Prediction Result:\n",
            "Classification: Sensitive\n",
            "Confidence: 65.6%\n",
            "\n",
            "Enter file path: q\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "class SensitivityPredictor:\n",
        "    def __init__(self, model_path):\n",
        "        self.model = joblib.load(model_path)\n",
        "        self.permission_map = {\n",
        "            '600': 'Restricted', '400': 'Restricted',\n",
        "            '644': 'Open', '755': 'Open', '777': 'Public'\n",
        "        }\n",
        "        self.department_map = {\n",
        "            'fin_user1': 'Finance', 'fin_user2': 'Finance',\n",
        "            'hr_admin': 'HR', 'hr_recruiter': 'HR',\n",
        "            'sysadmin': 'IT', 'devops': 'IT'\n",
        "        }\n",
        "\n",
        "    def _map_owner(self, username):\n",
        "        return self.department_map.get(username.split('_')[0], 'unknown')\n",
        "\n",
        "    def _map_permissions(self, mode):\n",
        "        return self.permission_map.get(mode[-3:], 'unknown')\n",
        "\n",
        "    def extract_features(self, file_path):\n",
        "        try:\n",
        "            stat = os.stat(file_path)\n",
        "            return {\n",
        "                'extension': os.path.splitext(file_path)[1].lower(),\n",
        "                'owner': self._map_owner(self._get_owner(file_path)),\n",
        "                'permissions': self._map_permissions(oct(stat.st_mode)[-3:]),\n",
        "                'size': stat.st_size / 1024,  # Convert to KB\n",
        "                'days_since_creation': (datetime.now() - datetime.fromtimestamp(stat.st_ctime)).days,\n",
        "                'days_since_modification': (datetime.now() - datetime.fromtimestamp(stat.st_mtime)).days,\n",
        "                'has_sensitive_keyword': any(kw in os.path.basename(file_path).lower() for kw in SENSITIVE_KEYWORDS)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def predict(self, file_path, threshold=0.6):\n",
        "        features = self.extract_features(file_path)\n",
        "        if not features:\n",
        "            return {\"error\": \"Could not process file\"}\n",
        "\n",
        "        df = pd.DataFrame([features])\n",
        "        proba = self.model.predict_proba(df)[0]\n",
        "\n",
        "        return {\n",
        "            \"prediction\": \"Sensitive\" if proba[1] > threshold else \"Non-Sensitive\",\n",
        "            \"confidence\": f\"{max(proba)*100:.1f}%\",\n",
        "            \"features\": features\n",
        "        }\n",
        "\n",
        "    def _get_owner(self, path):\n",
        "        try:\n",
        "            import pwd\n",
        "            return pwd.getpwuid(os.stat(path).st_uid).pw_name\n",
        "        except:\n",
        "            return \"unknown\"\n",
        "\n",
        "# Usage\n",
        "if __name__ == \"__main__\":\n",
        "    predictor = SensitivityPredictor('sensitivity_classifier.joblib')\n",
        "    file_path = input(\"Enter file path: \")\n",
        "    while(file_path != 'q'):\n",
        "      result = predictor.predict(file_path)\n",
        "\n",
        "      print(\"Prediction Result:\")\n",
        "      print(f\"Classification: {result['prediction']}\")\n",
        "      print(f\"Confidence: {result['confidence']}\")\n",
        "      # print(\"\\nMetadata Analysis:\")\n",
        "      # for k, v in result['features'].items():\n",
        "      #   print(f\"{k.replace('_', ' ').title()}: {v}\")\n",
        "      print()\n",
        "      file_path = input(\"Enter file path: \")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weightage to Keyword\n",
        "balance in directory levels(path mai keyword)\n"
      ],
      "metadata": {
        "id": "KfpbyeljOExs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "167TigtwOLrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsZkoth3TDNirUSuLhKEfL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}